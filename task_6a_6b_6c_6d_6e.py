# -*- coding: utf-8 -*-
"""TASK 6A - 6B - 6C - 6D - 6E

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DapUbH9H2UjKAqb60e-AS6HRCYyJINRB

TASK-6A: Please use the latest version of the AD dataset to provide the following outputs:

y : CDRGLOB
X : all columns except for the label
Train-test split: .80-.20 (please use the stratify parameter)
Cross-validation both with k=5 and k=10

Please compare and discuss the outputs obtained from the cross validation step by k=5 and k=10.
"""

import pandas as pd
import numpy as np

data = pd.read_excel('Temporary_data3_Left_Right_Copy.xlsx')
y = data['CDRGLOB']
X = data.drop('CDRGLOB',axis=1)

from sklearn.model_selection import train_test_split
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=1)

from sklearn.model_selection import cross_val_score
print("k=5 için: ", cross_val_score(model, X, y, cv=5), "\nOrtalama:",cross_val_score(model, X, y, cv=5).mean())
print("k=10 için: ", cross_val_score(model, X, y, cv=10), "\nOrtalama:",cross_val_score(model, X, y, cv=10).mean())

"""TASK-6B: Please perform a grid search run with the use of a ML algorithm (and its 3 parameters at least with 5 different values for each) you select as opposed to the Gaussian Naive Bayes algorithm. Then compare the outputs with respect to the accuracy values on the test dataset. """

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
model = DecisionTreeClassifier()                                                
model.fit(Xtrain, ytrain)  
y_model = model.predict(Xtest)
print("DecisionTreeClassifier default parametreler ile doğruluk oranı: ",accuracy_score(ytest, y_model))

from sklearn.model_selection import GridSearchCV

params = {'max_leaf_nodes': list(range(2,6)),'min_samples_split': [2, 3, 4, 5, 6], 'random_state': [2,4,6,8,10]}
gridCV = GridSearchCV(estimator=model, param_grid=[params] ,cv=5)
gridCV = gridCV.fit(Xtrain, ytrain)
print("Best score:", gridCV.best_score_)
print("En iyi parametreler: ", gridCV.best_params_)
y_model2 = gridCV.best_estimator_.fit(Xtrain, ytrain).predict(Xtest)
print("En iyi parametrelerle doğruluk oranı" , accuracy_score(ytest, y_model2))

"""TASK-6C: Please provide a visualization of the best algorithm with respect to the two of the dimensions in the dataset and please annotate the labels (separately for true labels and predicted labels in 2 different graphs). For instance, x-axis might be RPARCORT and y-axis might be LTEMPCOR."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.figure(figsize=(20, 5))
plt.subplot(1, 2, 1)
plt.scatter(Xtest["RPARCORT"], Xtest["LTEMPCOR"],c=ytest)
plt.colorbar(ticks=[0,1,2,3])
plt.title("Real values")
plt.ylabel("LTEMPCOR")
plt.xlabel("RPARCORT")
plt.subplots_adjust(wspace = 0.3)
plt.subplot(1, 2, 2)
plt.scatter(Xtest["RPARCORT"], Xtest["LTEMPCOR"],c=y_model2)
plt.colorbar(ticks=[0,1,2,3])
plt.title("Prediction values")
plt.ylabel("LTEMPCOR")
plt.xlabel("RPARCORT")
plt.show();

"""TASK-6D: Please apply one of the dimensionality reduction methods (PCA or isomap) and reduce the features matrix into 2 extracted dimensions. Then provide a visualization with respect to these dimensions. """

from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
pca_trans = pca.fit_transform(X)
plt.figure()
plt.scatter(pca_trans[:,0], pca_trans[:,1],c=y)
plt.colorbar(ticks=[0,1,2,3])
plt.title("CDRGLOB values for 2 features of PCA")
plt.ylabel("PCA 1")
plt.xlabel("PCA 2")
plt.show()

"""TASK-6E: Please perform one of the clustering techniques (k-means or GMM) on the dataset (on the features matrix) then again provide a visual illustration with respect to the features like age, education. 

"""

from sklearn.cluster import KMeans
model=KMeans(n_clusters=3)
model = model.fit(Xtrain,ytrain).predict(Xtest)

plt.figure(figsize=(20, 5))
plt.subplot(1, 2, 1)
plt.scatter(Xtest["RPARCORT"], Xtest["LTEMPCOR"],c=ytest)
plt.colorbar(ticks=[0,1,2,3])
plt.title("Real values")
plt.ylabel("LTEMPCOR")
plt.xlabel("RPARCORT")
plt.subplots_adjust(wspace = 0.3)
plt.subplot(1, 2, 2)
plt.scatter(Xtest["RPARCORT"], Xtest["LTEMPCOR"],c=model)
plt.colorbar(ticks=[0,1,2,3])
plt.title("Prediction values")
plt.ylabel("LTEMPCOR")
plt.xlabel("RPARCORT")
plt.show()
accuracy_score(ytest, model)